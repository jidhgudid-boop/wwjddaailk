"""
æµé‡æ”¶é›†å™¨æ¨¡å—
1MBæµé‡èµ·æ­¥ï¼Œ5åˆ†é’Ÿä¸ŠæŠ¥ä¸€æ¬¡ï¼Œä¸ŠæŠ¥åæ¸…é™¤æ•°æ®
"""
import asyncio
import time
import json
import logging
import os
from typing import Dict, Optional, Set
from collections import defaultdict
from datetime import datetime


class TrafficCollector:
    """è½»é‡çº§æµé‡æ”¶é›†å™¨ - 1MBèµ·æ­¥ï¼Œ5åˆ†é’Ÿä¸ŠæŠ¥ï¼Œä¸ŠæŠ¥åæ¸…é™¤"""
    
    def __init__(self, redis_manager, http_client_manager, logger, 
                 report_url: str, api_key: str = None):
        self.redis_manager = redis_manager
        self.http_client_manager = http_client_manager
        self.logger = logger
        self.report_url = report_url
        self.api_key = api_key
        
        # æµé‡æ”¶é›†é…ç½®
        self.MIN_BYTES_THRESHOLD = 1024 * 1024  # 1MBèµ·æ­¥é—¨æ§›ä¸ŠæŠ¥
        self.REPORT_INTERVAL = 300  # 300å³ 5åˆ†é’Ÿä¸ŠæŠ¥ä¸€æ¬¡
        
        # Workerèº«ä»½
        self.worker_id = f"worker_{os.getpid()}_{int(time.time())}"
        
        # æµé‡ç¼“å­˜ - åªè®°å½•è¶…è¿‡1MBçš„UID
        self._qualified_traffic: Dict[str, Dict] = {}
        
        # ä¸´æ—¶ç´¯ç§¯å™¨ - ç”¨äºåˆ¤æ–­æ˜¯å¦è¾¾åˆ°1MBé—¨æ§›
        self._accumulator: Dict[str, int] = defaultdict(int)
        
        # ç´¯ç§¯å™¨æ—¶é—´æˆ³ï¼ˆç”¨äºæ¸…ç†ï¼‰
        self._accumulator_timestamps: Dict[str, float] = {}
        
        # ç»Ÿè®¡ä¿¡æ¯
        self._stats = {
            'total_recorded_uids': 0,
            'total_reports_sent': 0,
            'total_bytes_reported': 0,
            'current_qualified_uids': 0,
            'reports_failed': 0,
            'accumulator_cleanups': 0
        }
        
        # ä»»åŠ¡æ§åˆ¶
        self._report_task: Optional[asyncio.Task] = None
        self._cleanup_task: Optional[asyncio.Task] = None
        self._running = False
        
        # æ¸…ç†è®¡æ•°å™¨
        self._cleanup_counter = 0
    
    def record_traffic(self, uid: str, bytes_transferred: int, file_type: str = "default", 
                      client_ip: str = "unknown", session_id: str = None):
        """è®°å½•æµé‡ - åªæœ‰è¶…è¿‡1MBçš„UIDæ‰ä¼šè¢«æ­£å¼è®°å½•"""
        try:
            if not uid or bytes_transferred <= 0:
                return
            
            current_time = time.time()
            
            # å¦‚æœå·²ç»åœ¨æ­£å¼è®°å½•ä¸­ï¼Œç›´æ¥ç´¯åŠ 
            if uid in self._qualified_traffic:
                traffic_data = self._qualified_traffic[uid]
                traffic_data['total_bytes'] += bytes_transferred
                traffic_data['request_count'] += 1
                traffic_data['last_activity'] = current_time
                
                # æ–‡ä»¶ç±»å‹ç»Ÿè®¡
                if file_type not in traffic_data['file_types']:
                    traffic_data['file_types'][file_type] = 0
                traffic_data['file_types'][file_type] += bytes_transferred
                
                # æ›´æ–°å”¯ä¸€å€¼ï¼ˆé™åˆ¶é›†åˆå¤§å°ï¼‰
                if len(traffic_data['unique_ips']) < 20:
                    traffic_data['unique_ips'].add(client_ip)
                if session_id and len(traffic_data['unique_sessions']) < 10:
                    traffic_data['unique_sessions'].add(session_id)
                
                return
            
            # å¦åˆ™å…ˆç´¯åŠ åˆ°ä¸´æ—¶ç´¯ç§¯å™¨
            self._accumulator[uid] += bytes_transferred
            
            # è®°å½•é¦–æ¬¡è§åˆ°çš„æ—¶é—´
            if uid not in self._accumulator_timestamps:
                self._accumulator_timestamps[uid] = current_time
            
            # æ£€æŸ¥æ˜¯å¦è¾¾åˆ°1MBé—¨æ§›
            if self._accumulator[uid] >= self.MIN_BYTES_THRESHOLD:
                # è¾¾åˆ°é—¨æ§›ï¼Œè½¬ç§»åˆ°æ­£å¼è®°å½•
                self._qualified_traffic[uid] = {
                    'total_bytes': self._accumulator[uid],
                    'request_count': 1,  # è¿™æ¬¡æ˜¯é¦–æ¬¡æ­£å¼è®°å½•
                    'file_types': {file_type: self._accumulator[uid]},
                    'unique_ips': {client_ip},
                    'unique_sessions': {session_id} if session_id else set(),
                    'start_time': self._accumulator_timestamps[uid],
                    'last_activity': current_time
                }
                
                # ä»ç´¯ç§¯å™¨ä¸­æ¸…é™¤
                del self._accumulator[uid]
                del self._accumulator_timestamps[uid]
                
                self._stats['total_recorded_uids'] += 1
                self.logger.info(f"ğŸ¯ UID {uid} è¾¾åˆ°1MBé—¨æ§›ï¼Œå¼€å§‹æ­£å¼è®°å½•æµé‡ (ç´¯ç§¯: {self._accumulator[uid] if uid in self._accumulator else 'N/A'} bytes)")
            
            # å®šæœŸæ¸…ç†ç´¯ç§¯å™¨
            self._maybe_cleanup_accumulator()
            
        except Exception as e:
            self.logger.error(f"è®°å½•æµé‡å¤±è´¥ uid={uid}: {str(e)}")
    
    def _maybe_cleanup_accumulator(self):
        """å®šæœŸæ¸…ç†ç´¯ç§¯å™¨ä¸­æœªè¾¾æ ‡çš„UID"""
        self._cleanup_counter += 1
        if self._cleanup_counter < 1000:  # æ¯1000æ¬¡è°ƒç”¨æ¸…ç†ä¸€æ¬¡
            return
        
        self._cleanup_counter = 0
        
        try:
            current_time = time.time()
            expired_uids = []
            
            # æ¸…ç†è¶…è¿‡10åˆ†é’Ÿè¿˜æœªè¾¾åˆ°1MBçš„UID
            for uid, timestamp in list(self._accumulator_timestamps.items()):
                if current_time - timestamp > 600:  # 10åˆ†é’Ÿ
                    expired_uids.append(uid)
            
            for uid in expired_uids:
                self._accumulator.pop(uid, None)
                self._accumulator_timestamps.pop(uid, None)
            
            if expired_uids:
                self._stats['accumulator_cleanups'] += 1
                self.logger.debug(f"æ¸…ç†äº† {len(expired_uids)} ä¸ªæœªè¾¾æ ‡UID")
                
        except Exception as e:
            self.logger.error(f"æ¸…ç†ç´¯ç§¯å™¨å¤±è´¥: {str(e)}")
    
    async def _send_traffic_report(self) -> bool:
        """å‘é€æµé‡ä¸ŠæŠ¥"""
        try:
            if not self._qualified_traffic:
                self.logger.debug("æ²¡æœ‰ç¬¦åˆæ¡ä»¶çš„æµé‡æ•°æ®éœ€è¦ä¸ŠæŠ¥")
                return True
            
            # å‡†å¤‡ä¸ŠæŠ¥æ•°æ®
            current_time = int(time.time())
            report_data = {
                'timestamp': current_time,
                'worker_id': self.worker_id,
                'report_interval_seconds': self.REPORT_INTERVAL,
                'min_bytes_threshold': self.MIN_BYTES_THRESHOLD,
                'total_qualified_uids': len(self._qualified_traffic),
                'traffic_details': []
            }
            
            total_bytes_in_report = 0
            total_requests_in_report = 0
            
            # æ„å»ºæ¯ä¸ªUIDçš„è¯¦ç»†æ•°æ®
            for uid, data in self._qualified_traffic.items():
                duration = max(1, int(data['last_activity'] - data['start_time']))
                
                uid_report = {
                    'uid': uid,
                    'total_bytes': data['total_bytes'],
                    'total_mb': round(data['total_bytes'] / (1024 * 1024), 2),
                    'request_count': data['request_count'],
                    'duration_seconds': duration,
                    'start_time': int(data['start_time']),
                    'last_activity': int(data['last_activity']),
                    'file_types': dict(data['file_types']),
                    'unique_ips': len(data['unique_ips']),
                    'unique_sessions': len(data['unique_sessions']),
                    'avg_bytes_per_request': int(data['total_bytes'] / max(data['request_count'], 1)),
                    'bytes_per_second': int(data['total_bytes'] / duration)
                }
                
                report_data['traffic_details'].append(uid_report)
                total_bytes_in_report += data['total_bytes']
                total_requests_in_report += data['request_count']
            
            # æ·»åŠ æ±‡æ€»ä¿¡æ¯
            report_data['summary'] = {
                'total_bytes': total_bytes_in_report,
                'total_mb': round(total_bytes_in_report / (1024 * 1024), 2),
                'total_requests': total_requests_in_report,
                'avg_bytes_per_uid': int(total_bytes_in_report / len(self._qualified_traffic)),
                'report_generated_at': datetime.utcfromtimestamp(current_time).strftime('%Y-%m-%d %H:%M:%S UTC')
            }
            
            # å‘é€HTTPè¯·æ±‚
            client = await self.http_client_manager.get_client()
            headers = {
                'Content-Type': 'application/json',
                'User-Agent': f'TrafficCollector/1.0 Worker-{self.worker_id}',
                'X-Report-Time': str(current_time)
            }
            
            if self.api_key:
                headers['Authorization'] = f'Bearer {self.api_key}'
            
            self.logger.debug(f"å‡†å¤‡ä¸ŠæŠ¥æµé‡æ•°æ®: {len(self._qualified_traffic)} ä¸ªUID, æ€»è®¡ {total_bytes_in_report:,} bytes")
            
            response = await client.post(
                self.report_url,
                json=report_data,
                headers=headers,
                timeout=30
            )
            
            if response.status_code == 200:
                response_text = response.text
                
                # ä¸ŠæŠ¥æˆåŠŸ - æ¸…é™¤æ‰€æœ‰æ•°æ®
                reported_uids = len(self._qualified_traffic)
                self._qualified_traffic.clear()
                
                self._stats['total_reports_sent'] += 1
                self._stats['total_bytes_reported'] += total_bytes_in_report
                self._stats['current_qualified_uids'] = 0
                
                self.logger.info(f"âœ… æµé‡ä¸ŠæŠ¥æˆåŠŸ: {reported_uids} ä¸ªUID, æ€»æµé‡: {total_bytes_in_report:,} bytes ({total_bytes_in_report/(1024*1024):.1f}MB)")
                self.logger.debug(f"ä¸ŠæŠ¥å“åº”å‰100å­—ç¬¦: {response_text[:100]}...")
                
                return True
            else:
                error_text = response.text
                self.logger.error(f"âŒ ä¸ŠæŠ¥å¤±è´¥ HTTP {response.status_code}: {error_text[:200]}...")
                self._stats['reports_failed'] += 1
                return False
                    
        except Exception as e:
            self.logger.error(f"âŒ å‘é€æµé‡ä¸ŠæŠ¥å¤±è´¥: {str(e)}")
            import traceback
            self.logger.debug(f"ä¸ŠæŠ¥å¼‚å¸¸è¯¦æƒ…: {traceback.format_exc()}")
            self._stats['reports_failed'] += 1
            return False
    
    async def _report_loop(self):
        """ä¸ŠæŠ¥å¾ªç¯ä»»åŠ¡"""
        self.logger.info(f"ğŸ”„ å¼€å§‹æµé‡ä¸ŠæŠ¥å¾ªç¯ï¼Œé—´éš”: {self.REPORT_INTERVAL}ç§’")
        
        while self._running:
            try:
                cycle_start = time.time()
                
                # æ‰§è¡Œä¸ŠæŠ¥
                await self._send_traffic_report()
                
                # è®¡ç®—ç­‰å¾…æ—¶é—´
                elapsed = time.time() - cycle_start
                sleep_time = max(0, self.REPORT_INTERVAL - elapsed)
                
                if sleep_time > 0:
                    await asyncio.sleep(sleep_time)
                else:
                    self.logger.warning(f"âš ï¸ ä¸ŠæŠ¥å‘¨æœŸè¶…æ—¶: è€—æ—¶ {elapsed:.2f}sï¼Œè¶…è¿‡é—´éš” {self.REPORT_INTERVAL}s")
                
            except asyncio.CancelledError:
                self.logger.info("ğŸ“¤ æµé‡ä¸ŠæŠ¥ä»»åŠ¡è¢«å–æ¶ˆ")
                break
            except Exception as e:
                self.logger.error(f"âŒ ä¸ŠæŠ¥å¾ªç¯é”™è¯¯: {str(e)}")
                await asyncio.sleep(60)  # é”™è¯¯æ—¶ç­‰å¾…1åˆ†é’Ÿå†é‡è¯•
    
    async def _cleanup_loop(self):
        """å®šæœŸæ¸…ç†ä»»åŠ¡"""
        while self._running:
            try:
                await asyncio.sleep(300)  # æ¯5åˆ†é’Ÿæ¸…ç†ä¸€æ¬¡
                
                if not self._running:
                    break
                
                # æ‰§è¡Œæ¸…ç†
                current_time = time.time()
                expired_uids = []
                
                for uid, timestamp in list(self._accumulator_timestamps.items()):
                    if current_time - timestamp > 1800:  # 30åˆ†é’Ÿæœªè¾¾æ ‡åˆ™æ¸…ç†
                        expired_uids.append(uid)
                
                for uid in expired_uids:
                    self._accumulator.pop(uid, None)
                    self._accumulator_timestamps.pop(uid, None)
                
                if expired_uids:
                    self.logger.info(f"ğŸ§¹ å®šæœŸæ¸…ç†äº† {len(expired_uids)} ä¸ªé•¿æœŸæœªè¾¾æ ‡çš„UID")
                    
            except asyncio.CancelledError:
                break
            except Exception as e:
                self.logger.error(f"å®šæœŸæ¸…ç†ä»»åŠ¡é”™è¯¯: {str(e)}")
    
    async def start(self):
        """å¯åŠ¨æµé‡æ”¶é›†å™¨"""
        if self._running:
            self.logger.warning("æµé‡æ”¶é›†å™¨å·²ç»åœ¨è¿è¡Œä¸­")
            return
        
        self._running = True
        
        # å¯åŠ¨ä¸ŠæŠ¥ä»»åŠ¡
        self._report_task = asyncio.create_task(self._report_loop())
        
        # å¯åŠ¨æ¸…ç†ä»»åŠ¡
        self._cleanup_task = asyncio.create_task(self._cleanup_loop())
        
        self.logger.info(f"ğŸš€ æµé‡æ”¶é›†å™¨å¯åŠ¨æˆåŠŸ")
        self.logger.info(f"ğŸ“Š é…ç½®å‚æ•°:")
        self.logger.info(f"   - Worker ID: {self.worker_id}")
        self.logger.info(f"   - æµé‡é—¨æ§›: {self.MIN_BYTES_THRESHOLD/(1024*1024):.1f}MB")
        self.logger.info(f"   - ä¸ŠæŠ¥é—´éš”: {self.REPORT_INTERVAL}ç§’")
        self.logger.info(f"   - ä¸ŠæŠ¥URL: {self.report_url}")
        self.logger.info(f"   - APIå¯†é’¥: {'å·²é…ç½®' if self.api_key else 'æœªé…ç½®'}")
    
    async def stop(self):
        """åœæ­¢æ”¶é›†å™¨å¹¶å‘é€æœ€åçš„æ•°æ®"""
        if not self._running:
            return
        
        self.logger.info("ğŸ›‘ æ­£åœ¨åœæ­¢æµé‡æ”¶é›†å™¨...")
        self._running = False
        
        # åœæ­¢å®šæ—¶ä»»åŠ¡
        if self._report_task:
            self._report_task.cancel()
            try:
                await self._report_task
            except asyncio.CancelledError:
                pass
        
        if self._cleanup_task:
            self._cleanup_task.cancel()
            try:
                await self._cleanup_task
            except asyncio.CancelledError:
                pass
        
        # å‘é€æœ€åçš„æ•°æ®
        if self._qualified_traffic:
            self.logger.info(f"ğŸ“¤ å‘é€æœ€åçš„æµé‡æ•°æ®: {len(self._qualified_traffic)} ä¸ªUID")
            await self._send_traffic_report()
        
        self.logger.info(f"ğŸ›‘ æµé‡æ”¶é›†å™¨å·²åœæ­¢")
        self.logger.info(f"ğŸ“ˆ æœ€ç»ˆç»Ÿè®¡: è®°å½•äº† {self._stats['total_recorded_uids']} ä¸ªUID, å‘é€äº† {self._stats['total_reports_sent']} æ¬¡æŠ¥å‘Š")
    
    def get_current_status(self) -> Dict:
        """è·å–å½“å‰çŠ¶æ€"""
        self._stats['current_qualified_uids'] = len(self._qualified_traffic)
        
        current_traffic_summary = None
        if self._qualified_traffic:
            total_bytes = sum(d['total_bytes'] for d in self._qualified_traffic.values())
            total_requests = sum(d['request_count'] for d in self._qualified_traffic.values())
            current_traffic_summary = {
                'total_bytes': total_bytes,
                'total_mb': round(total_bytes / (1024 * 1024), 2),
                'total_requests': total_requests,
                'avg_bytes_per_uid': int(total_bytes / len(self._qualified_traffic))
            }
        
        return {
            'worker_id': self.worker_id,
            'running': self._running,
            'config': {
                'min_threshold_mb': self.MIN_BYTES_THRESHOLD / (1024 * 1024),
                'report_interval_seconds': self.REPORT_INTERVAL,
                'report_url': self.report_url,
                'api_key_configured': bool(self.api_key)
            },
            'current_state': {
                'qualified_uids': len(self._qualified_traffic),
                'pending_accumulator_uids': len(self._accumulator),
                'next_report_in_seconds': self.REPORT_INTERVAL  # è¿‘ä¼¼å€¼
            },
            'statistics': self._stats.copy(),
            'current_traffic_summary': current_traffic_summary
        }


# è¾…åŠ©å‡½æ•°
async def init_traffic_collector(redis_manager, http_client_manager, logger, 
                               report_url: str, api_key: str = None) -> TrafficCollector:
    """åˆå§‹åŒ–æµé‡æ”¶é›†å™¨"""
    collector = TrafficCollector(
        redis_manager=redis_manager,
        http_client_manager=http_client_manager,
        logger=logger,
        report_url=report_url,
        api_key=api_key
    )
    await collector.start()
    return collector